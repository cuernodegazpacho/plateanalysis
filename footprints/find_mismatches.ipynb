{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71736c5",
   "metadata": {},
   "source": [
    "# Find mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8506af15",
   "metadata": {},
   "source": [
    "Source files are created from the APPLAUSE database by this query:\n",
    "\n",
    "```\n",
    "SELECT * \n",
    "FROM applause_dr4.source \n",
    "WHERE plate_id = 19019\n",
    "ORDER BY source_id\n",
    "```\n",
    "with another separate call for the source_calib table.\n",
    "\n",
    "We look for sources that show up in two separate plates. The ones that don't are the candidates we should look in more detail.\n",
    "\n",
    "The script exploits parallelism to expedite the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660cecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "import csv\n",
    "from math import sqrt\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits import Header, Card\n",
    "from astropy.table import Table, join\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord, Longitude, Latitude\n",
    "\n",
    "from regions import PolygonSkyRegion\n",
    "from mocpy import MOC\n",
    "\n",
    "from settings import get_parameters, fname, current_dataset\n",
    "from library import Worker, Worker2, is_in_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ea9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "in_jupyter = is_in_jupyter()\n",
    "\n",
    "print(in_jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d1f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nproc': 8,\n",
       " 'sextractor_flags': 4,\n",
       " 'model_prediction': 0.8,\n",
       " 'max_flux_threshold': 0.3,\n",
       " 'elongation': 1.5,\n",
       " 'annular_bin': 7,\n",
       " 'flag_rim': 0,\n",
       " 'min_acceptable_flux': 25000,\n",
       " 'min_fwhm': 5.0,\n",
       " 'max_fwhm': 7.5,\n",
       " 'qfit_max': 5.0,\n",
       " 'cfit_max': 5.0,\n",
       " 'invert_east': [False, False],\n",
       " 'invert_north': [False, False],\n",
       " 'table1': 'sources_9319.csv',\n",
       " 'table2': 'sources_9320.csv',\n",
       " 'table1_calib': 'sources_calib_9319.csv',\n",
       " 'table2_calib': 'sources_calib_9320.csv',\n",
       " 'table_matched': 'table_match_9319_9320.fits',\n",
       " 'table_non_matched': 'table_nomatch_9319_9320.fits',\n",
       " 'table_psf_nonmatched': 'table_psf_nomatch_9319_9320.fits',\n",
       " 'image1': 'GS00768_x.fits',\n",
       " 'image2': 'GS00769_x.fits'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = get_parameters(current_dataset)\n",
    "par"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b19a7",
   "metadata": {},
   "source": [
    "## Read source tables generated by APPLAUSE database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ff81b",
   "metadata": {},
   "source": [
    "From both **applause_dr4.source** and **applause_dr4.source_calib**. We need both, but we cannot get a joined version directly from APPLAUSE. Maybe they are limiting the output size. In any way, we get both and join them locally here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89602574",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_src_1 = Table.read(fname(par['table1']), format='ascii.csv')\n",
    "table_src_2 = Table.read(fname(par['table2']), format='ascii.csv')\n",
    "\n",
    "table_calib_1 = Table.read(fname(par['table1_calib']), format='ascii.csv')\n",
    "table_calib_2 = Table.read(fname(par['table2_calib']), format='ascii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = join(table_calib_1, table_src_1, keys='source_id')\n",
    "table_2 = join(table_calib_2, table_src_2, keys='source_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(table_1), len(table_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743f318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9a8d9",
   "metadata": {},
   "source": [
    "## Remove undesirable sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c4fa8",
   "metadata": {},
   "source": [
    "Use a variety of criteria from SEXTRACTOR to get rid of possible contaminants.\n",
    "\n",
    "We want to clean the first table only, since only well-defined star images from the first image should be present in our sample. The second table is taken as is; we want to see everything that is near the sources selected from the firsr table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1copy = table_1.copy()\n",
    "table_2copy = table_2.copy()\n",
    "\n",
    "# Extraction flags \n",
    "mask = table_1copy['sextractor_flags_1'] <= par['sextractor_flags']\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "# Likelihood of being valid star image \n",
    "mask = table_1copy['model_prediction_1'] > par['model_prediction']\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "# Round objects \n",
    "mask = table_1copy['elongation'] < par['elongation']\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "# Ring\n",
    "mask = table_1copy['annular_bin_1'] <= par['annular_bin']\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "# Is source at plate rim ?\n",
    "mask = table_1copy['flag_rim'] == par['flag_rim']\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "# flux threshold - set it to fraction of max peak in image\n",
    "flux_threshold = max(table_1copy['flux_max']) * par['max_flux_threshold']\n",
    "mask = table_1copy['flux_max'] > flux_threshold\n",
    "table_1copy = table_1copy[mask]\n",
    "\n",
    "print(len(table_1copy), len(table_2copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ad2ee",
   "metadata": {},
   "source": [
    "## Remove scanner artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68c630",
   "metadata": {},
   "source": [
    "When plates were scanned twice or more, usually in two directions perpendicular to each other, all scans are included in a single table. Stars and artifacts *on* the plate will share the same celestial coordinates in both scans, but scanner-induced artifacts won't, because they move in x,y when the plate is rotated 90 deg. Thus we remove all rows that have no duplicates.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af31a5",
   "metadata": {},
   "source": [
    "To expedite the search, we split the job among all available performance CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of processors\n",
    "nproc = par['nproc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fff3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matching code lives in file library.py - it has to be kept in a separate \n",
    "# file because of restrictions in name space imposed by the parallelization library.\n",
    "\n",
    "# Here, the parallelized code stores its product, the list of indices that have duplicates.\n",
    "matched = []\n",
    "\n",
    "# callback function to collect results from parallel workers\n",
    "def collect_result(results):\n",
    "    matched.extend(results)\n",
    "    \n",
    "results = []\n",
    "pool = Pool(nproc)\n",
    "\n",
    "row_range = int(len(table_1copy) / nproc)\n",
    "\n",
    "for p in range(nproc):\n",
    "    # workers are defined over ranges of rows in the table_1copy table\n",
    "    worker = Worker2(\"w\"+str(p), table_1copy, int(p*row_range), int((p+1)*row_range))\n",
    "\n",
    "    r = pool.apply_async(worker, callback=collect_result)\n",
    "    results.append(r)\n",
    "\n",
    "for r in results:\n",
    "    r.wait()\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5708fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matched), \" rows have duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a small number of duplicates, or none, was detected, ignore them.\n",
    "if len(matched) > len(table_1copy) / 10:\n",
    "\n",
    "    # lots of duplicates: keep only the duplicated rows\n",
    "    table_1copy = table_1copy[matched]\n",
    "\n",
    "print(len(table_1copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d9fac",
   "metadata": {},
   "source": [
    "## Look for matches between 1st and 2nd tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8da944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Same code as above (can't be put in a function to avoid duplication).\n",
    "#\n",
    "# It generates the list of indices (in the first table) of all objects \n",
    "# for which it could find at least one matching entry in the second table.\n",
    "matched = []\n",
    "\n",
    "results = []\n",
    "pool = Pool(nproc)\n",
    "\n",
    "row_range = int(len(table_1copy) / nproc)\n",
    "\n",
    "for p in range(nproc):\n",
    "    # workers are defined over ranges of rows in the table_1copy table\n",
    "    worker = Worker(\"w\"+str(p), table_1copy, table_2copy, int(p*row_range), int((p+1)*row_range))\n",
    "\n",
    "    r = pool.apply_async(worker, callback=collect_result)\n",
    "    results.append(r)\n",
    "\n",
    "for r in results:\n",
    "    r.wait()\n",
    "\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matched), \" sources detected in 1st plate with a match in 2nd plate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc6ba4",
   "metadata": {},
   "source": [
    "## Get the non-matched objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bef084",
   "metadata": {},
   "source": [
    "Remove the matched rows from the first table. Whatever remains, is the table of objects for which a match couldn't be found.\n",
    "\n",
    "Remove duplicated indices first, and save original table since removal is done in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3 = table_1copy.copy()\n",
    "\n",
    "m = list(dict.fromkeys(matched))\n",
    "table_3.remove_rows(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7c947",
   "metadata": {},
   "source": [
    "## Write result to FITS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_3.write(fname(par['table_non_matched']), format='fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfec0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with the matched objects only (selected by index array m)\n",
    "\n",
    "table_1copy[m].write(fname(par['table_matched']), format='fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1copy[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd7891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
